Resultados Primeiros testes
5 trials e 4 épocas:
1) LSTM Puro: 0.00039736265898682177
2) LSTM + dropout: 0.013068703934550285
3) LSTM + LSTM: 0.0004917564801871777
4) LSTM + dropout + LSTM + dropout: 0.001145733636803925




Roadmap:
- Comentar os códigos inteiros - OK
- RODANDO: Experimentos Llama. - O primeiro estudo está funcionando. Precisa criar as demais arquiteturas e testar tudo. Rodar tudo rápido e gerar um sqlite. Copiar o arquivo e abrir no dashboard local para ver se está tudo bem, depois aplicar os parâmetros do rodrigo e deixar rodando.
- PAREI AQUI: Experimentos Thommas:
    - Pegar o dataset de combustão como Daniel - OK
    - Analisar e tratar os datasets
    - Calcular as colunas de emissões segundo as fórmulas do github
    - Usar a ideia do Thommas para treinar os modelos em cima do novo dataset (combustão) e no dataset de agora (elétrico).
    - Aplicar o EsquemaProjeto.jpeg com as features estimadas do elétrico pelo nosso modelo e verificar o erro da CO2 emissions.
- Avaliar a feature importance para o LSTM e verificar se consigo saber quais as variáveis mais importantes.
- Avaliar o que muda se embaralhar a ordem das trips na entrada do treinamento.




Experimento Llama:
- Trials:
	- 100 trials
- Epochs:
	- 1000 com early stopping (patience 5)
- Arquiteturas:
	- São 3 estudos só: 
		- 1 a 3 camadas de LSTM todas com dropout
	- Adicionar um quarto estudo de LayerNorm
		- LSTM - Norm - LSTM - Norm - LSTM - Norm - Dense - Norm - Dense(saída)
- Parâmetros e Intervalos:
	- Dense: Ativação relu ou tanh
	- LSTM não muda a ativação
	- LSTM units: 16 a 64 com step de 16
	- Dense units: 16 a 64 com step de 16
	- Dropout recurrent: categorico 0, .25 e .5 
	- Optimizer: Adam com learning_rate categorico: 0.1, 0.01, 0.001
	- Batch_size: 32, 64, 128 e 256




optuna-dashboard sqlite:///lstm.sqlite3 --port 8880      
Acessar em http://localhost:8880/
